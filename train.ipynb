{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Small C3D model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 40, 50, 88, 32)    2624      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 40, 25, 44, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 40, 25, 44, 64)    55360     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 20, 12, 22, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 20, 12, 22, 128)   221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 10, 6, 11, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 10, 6, 11, 128)    442496    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 5, 3, 5, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2457856   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 13)                3341      \n",
      "=================================================================\n",
      "Total params: 3,248,781\n",
      "Trainable params: 3,248,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Starting training\n",
      "Epoch 1/100\n",
      "178/178 [==============================] - 547s 3s/step - loss: 2.5643 - acc: 0.0841 - top_k_categorical_accuracy: 0.4073 - val_loss: 2.5607 - val_acc: 0.0945 - val_top_k_categorical_accuracy: 0.4139\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.56072, saving model to model_name-001-2.564.hdf5\n",
      "Epoch 2/100\n",
      "178/178 [==============================] - 440s 2s/step - loss: 2.5634 - acc: 0.0787 - top_k_categorical_accuracy: 0.3965 - val_loss: 2.5666 - val_acc: 0.0693 - val_top_k_categorical_accuracy: 0.3655\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.56072\n",
      "Epoch 3/100\n",
      "178/178 [==============================] - 411s 2s/step - loss: 2.2895 - acc: 0.2185 - top_k_categorical_accuracy: 0.6236 - val_loss: 1.8906 - val_acc: 0.3571 - val_top_k_categorical_accuracy: 0.7479\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.56072 to 1.89056, saving model to model_name-003-2.290.hdf5\n",
      "Epoch 4/100\n",
      "178/178 [==============================] - 400s 2s/step - loss: 1.5158 - acc: 0.4930 - top_k_categorical_accuracy: 0.8760 - val_loss: 1.5539 - val_acc: 0.4832 - val_top_k_categorical_accuracy: 0.8298\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.89056 to 1.55391, saving model to model_name-004-1.516.hdf5\n",
      "Epoch 5/100\n",
      "178/178 [==============================] - 398s 2s/step - loss: 1.0535 - acc: 0.6587 - top_k_categorical_accuracy: 0.9428 - val_loss: 0.9876 - val_acc: 0.6681 - val_top_k_categorical_accuracy: 0.9391\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.55391 to 0.98763, saving model to model_name-005-1.053.hdf5\n",
      "Epoch 6/100\n",
      "178/178 [==============================] - 396s 2s/step - loss: 0.7791 - acc: 0.7480 - top_k_categorical_accuracy: 0.9645 - val_loss: 0.8052 - val_acc: 0.7605 - val_top_k_categorical_accuracy: 0.9412\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.98763 to 0.80522, saving model to model_name-006-0.779.hdf5\n",
      "Epoch 7/100\n",
      "178/178 [==============================] - 397s 2s/step - loss: 0.5886 - acc: 0.8080 - top_k_categorical_accuracy: 0.9843 - val_loss: 0.7879 - val_acc: 0.7500 - val_top_k_categorical_accuracy: 0.9643\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.80522 to 0.78788, saving model to model_name-007-0.589.hdf5\n",
      "Epoch 8/100\n",
      "178/178 [==============================] - 396s 2s/step - loss: 0.4616 - acc: 0.8551 - top_k_categorical_accuracy: 0.9886 - val_loss: 0.6034 - val_acc: 0.8193 - val_top_k_categorical_accuracy: 0.9790\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.78788 to 0.60341, saving model to model_name-008-0.462.hdf5\n",
      "Epoch 9/100\n",
      "178/178 [==============================] - 397s 2s/step - loss: 0.3585 - acc: 0.8830 - top_k_categorical_accuracy: 0.9934 - val_loss: 0.6892 - val_acc: 0.7899 - val_top_k_categorical_accuracy: 0.9832\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.60341\n",
      "Epoch 10/100\n",
      "178/178 [==============================] - 396s 2s/step - loss: 0.2837 - acc: 0.9095 - top_k_categorical_accuracy: 0.9958 - val_loss: 1.1489 - val_acc: 0.7479 - val_top_k_categorical_accuracy: 0.9664\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.60341\n",
      "Epoch 11/100\n",
      "178/178 [==============================] - 397s 2s/step - loss: 0.2234 - acc: 0.9268 - top_k_categorical_accuracy: 0.9982 - val_loss: 0.6620 - val_acc: 0.8277 - val_top_k_categorical_accuracy: 0.9811\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.60341\n",
      "Epoch 12/100\n",
      "178/178 [==============================] - 397s 2s/step - loss: 0.1849 - acc: 0.9416 - top_k_categorical_accuracy: 0.9982 - val_loss: 0.6708 - val_acc: 0.8445 - val_top_k_categorical_accuracy: 0.9811\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.60341\n",
      "Epoch 13/100\n",
      "178/178 [==============================] - 396s 2s/step - loss: 0.1375 - acc: 0.9571 - top_k_categorical_accuracy: 0.9996 - val_loss: 0.8272 - val_acc: 0.8361 - val_top_k_categorical_accuracy: 0.9811\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.60341\n",
      "Epoch 14/100\n",
      "178/178 [==============================] - 396s 2s/step - loss: 0.1012 - acc: 0.9699 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8680 - val_acc: 0.8214 - val_top_k_categorical_accuracy: 0.9832\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.60341\n",
      "Epoch 15/100\n",
      "178/178 [==============================] - 397s 2s/step - loss: 0.1041 - acc: 0.9669 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8645 - val_acc: 0.8067 - val_top_k_categorical_accuracy: 0.9790\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.60341\n",
      "Epoch 16/100\n",
      "178/178 [==============================] - 396s 2s/step - loss: 0.0776 - acc: 0.9719 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.0807 - val_acc: 0.7899 - val_top_k_categorical_accuracy: 0.9664\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.60341\n",
      "Epoch 17/100\n",
      "178/178 [==============================] - 396s 2s/step - loss: 0.0612 - acc: 0.9785 - top_k_categorical_accuracy: 0.9998 - val_loss: 1.0670 - val_acc: 0.8214 - val_top_k_categorical_accuracy: 0.9622\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.60341\n",
      "Epoch 18/100\n",
      "178/178 [==============================] - 397s 2s/step - loss: 0.0818 - acc: 0.9753 - top_k_categorical_accuracy: 0.9996 - val_loss: 0.7609 - val_acc: 0.8466 - val_top_k_categorical_accuracy: 0.9853\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.60341\n",
      "<keras.callbacks.History object at 0x7ff58daec978>\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "from models import ModelLoader\n",
    "from data import CNN3DDataLoader\n",
    "import time\n",
    "import os\n",
    "\n",
    "def save_history(history,  name):\n",
    "    print (history)\n",
    "    loss=history.history['loss']\n",
    "    acc=history.history['acc']\n",
    "    val_loss=history.history['val_loss']\n",
    "    val_acc=history.history['val_acc']\n",
    "    nb_epoch=len(acc)\n",
    "\n",
    "    with open(os.path.join(\"/media/neuzan/Backups/Project Stuffs/Major/New folder/\", 'result_{}.txt'.format(name)), 'w') as fp:\n",
    "        fp.write('epoch\\tloss\\tacc\\tval_loss\\tval_acc\\n')\n",
    "        for i in range(nb_epoch):\n",
    "            fp.write('{}\\t{}\\t{}\\t{}\\t{}\\n'.format(\n",
    "                i, loss[i], acc[i], val_loss[i], val_acc[i]))\n",
    "\n",
    "\n",
    "\n",
    "labels_want = ['Swiping Left',\n",
    "              'Swiping Right',\n",
    "              'Swiping Down',\n",
    "              'Swiping Up',\n",
    "              'Rolling Hand Forward',\n",
    "              'Rolling Hand Backward',\n",
    "               'Turning Hand Clockwise',\n",
    "               'Turning Hand Counterclockwise',\n",
    "               'Zooming In With Full Hand',\n",
    "               'Zooming Out With Full Hand',\n",
    "               'Shaking Hand',\n",
    "               'Drumming Fingers',\n",
    "               'No gesture',\n",
    "              ]\n",
    "\n",
    "\n",
    "def train(model_name):\n",
    "    # Data parameters\n",
    "    #data_dir = r'C:\\Users\\Lorenz\\Documents\\Coding\\data\\jester_hand_gestures'\n",
    "    data_dir = r'/media/neuzan/Backups/Project Stuffs/Major/New folder/20bn-jester-v1'\n",
    "    seq_length =40\n",
    "    n_videos = {'train': 5000, 'validation': 500}\n",
    "    image_size=(50, 88)\n",
    "\n",
    "    # Training parameters\n",
    "    n_epochs = 100\n",
    "    batch_size = 28\n",
    "    steps_per_epoch = n_videos['train'] // batch_size\n",
    "    val_steps = n_videos['validation'] // batch_size\n",
    "\n",
    "    # Load data generators\n",
    "    data = CNN3DDataLoader(data_dir, seq_length=seq_length, n_videos=n_videos, labels = labels_want)\n",
    "    train_gen = data.sequence_generator('train', batch_size, image_size)\n",
    "    validation_gen = data.sequence_generator('validation', batch_size, image_size)\n",
    "\n",
    "    #optimizer = keras.optimizers.SGD(lr=0.1, momentum=0.9, decay= 1e-6, nesterov=True)\n",
    "    #Load model\n",
    "    optimizer = keras.optimizers.Adadelta()\n",
    "    ml = ModelLoader(data.n_labels, data.seq_length, model_name, image_size=image_size, optimizer = optimizer)\n",
    "    model = ml.model\n",
    "\n",
    "    #Define callbacks\n",
    "\n",
    "    checkpointer = ModelCheckpoint(\n",
    "        filepath='model_name' + '-{epoch:03d}-{loss:.3f}.hdf5',\n",
    "        verbose=1,\n",
    "        save_best_only=True)\n",
    "    tb = TensorBoard(log_dir='./models/logs')\n",
    "    early_stopper = EarlyStopping(patience=10)\n",
    "    csv_logger = CSVLogger('./models/logs/' + model_name + '-' + 'training-' + \\\n",
    "        str(time.time()) + '.log')\n",
    "\n",
    "    callbacks = [tb, early_stopper, csv_logger, checkpointer]\n",
    "\n",
    "    # Training\n",
    "    print('Starting training')\n",
    "\n",
    "    history = model.fit_generator(\n",
    "        generator=train_gen,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        #sample_per_epoch= 200,\n",
    "        epochs=n_epochs,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=validation_gen,\n",
    "        validation_steps=val_steps,\n",
    "    )\n",
    "\n",
    "\n",
    "    model.save('./my_model.h5')\n",
    "    \n",
    "    save_history(history,\"c3d\")\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "#     train(\"c3d\")\n",
    "    train(\"small_c3d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.backend.tensorflow_backend import get_session\n",
    "import tensorflow\n",
    "\n",
    "# Reset Keras Session\n",
    "def reset_keras():\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "    try:\n",
    "        del model # this is from global space - change this as you need\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(gc.collect()) # if it's done something you should see a number being outputted\n",
    "\n",
    "    # use the same config as you used to create the session\n",
    "    config = tensorflow.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    config.gpu_options.visible_device_list = \"0\"\n",
    "    set_session(tensorflow.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
